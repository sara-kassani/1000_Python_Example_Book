{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing in Python\n",
    "###Tanmoy Dasgupta\n",
    "thetdg@live.com | Assistant Professor | Department of Electrical Engineering | Techno India University, Kolkata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I colud not get the sepll checekr wroikng. So this ntoebook mgiht cnotain erorrs / toyps***.\n",
    "\n",
    "This tutorial is supposed to be an introduction to the different scientific packages in python that can be utilized to perform different tasks related to image processing. I have inherently assumed that the reader already has good exposure on core **Python** and some exposure on **Numpy**, **Scipy** and **Matplotlib**. It is also assumed that the reader knows how to start **IPython Notebook**s. \n",
    "\n",
    "This notebook contains materails that are useful and new. However, things that are useful are not new and the things that are new are not always useful. Feel free to improve it and send me suggestions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Packages You Need\n",
    "[Python 2.7 or Python 3.4](https://www.python.org/)\n",
    "\n",
    "Choose Python 2.7 is you want to settle with the past. Choose 3.4 if you want to go with the future.\n",
    "\n",
    "[NumPy](http://www.numpy.org/)\n",
    "\n",
    "NumPy is the fundamental package for scientific computing with Python. It contains among other things:\n",
    "1. a powerful N-dimensional array object\n",
    "2. sophisticated (broadcasting) functions\n",
    "3. tools for integrating C/C++ and Fortran code\n",
    "4. useful linear algebra, Fourier transform, and random number capabilities\n",
    "\n",
    "[SciPy](http://www.scipy.org/) \n",
    "\n",
    "The SciPy library is one of the core packages that make up the SciPy stack. It provides many user-friendly and efficient numerical routines such as routines for numerical integration and optimization.\n",
    "\n",
    "[Matplotlib](http://matplotlib.org/) \n",
    "\n",
    "Matplotlib is a python 2D and 3D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. matplotlib can be used in python scripts, the python and ipython shell (ala MATLAB® or Mathematica®), web application servers, and different graphical user interface toolkits.\n",
    "\n",
    "[IPython](http://ipython.org/) \n",
    "\n",
    "IPython provides a rich architecture for interactive computing with:\n",
    "\n",
    "1. Powerful interactive shells (terminal and Qt-based).\n",
    "2. A browser-based notebook with support for code, rich text, mathematical expressions, inline plots and other rich media.\n",
    "3. Support for interactive data visualization and use of GUI toolkits.\n",
    "4. Flexible, embeddable interpreters to load into your own projects.\n",
    "5. Easy to use, high performance tools for parallel computing.\n",
    "\n",
    "[Python Imaging Library](https://github.com/python-pillow/Pillow) and [Scikit-Image](http://scikit-image.org/)\n",
    "\n",
    "These packages (among many others) have custom modules for image processing.\n",
    "\n",
    "[OpenCV](http://opencv.org/)\n",
    "\n",
    "OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products. The library has more than 2500 optimized algorithms, which includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms. It has C++, C, Python, Java and MATLAB interfaces and supports Windows, Linux, Android and Mac OS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Installing\n",
    "\n",
    "Installing all these packages might seem a little too much! Don't worry. You can install all of the above (and many other packages) just by downloading and installing any of the following **Python Distributions** : \n",
    "\n",
    "[Continuum Anaconda](http://continuum.io/downloads) Free (as in 'Freedom'). Both Python 2.7 and 3.4 are available. Availabe for Linux, Mac and Windows.\n",
    "\n",
    "[Enthought Canopy](https://www.enthought.com/products/canopy/) Free  + Subscription based. Only Python 2.7. Availabe for Linux, Mac and Windows. Full featured product subscription is freely availabe for **Academic** use.\n",
    "\n",
    "[WinPython](http://winpython.sourceforge.net/) Portable. Free. Both Python 2.7 and 3.4 are available. Windows only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Getting Started\n",
    "\n",
    "Unlike almost all other IPython notebooks, I will **NOT** import **Pylab Magic**. But if you really want to, you can do it by uncommenting (removing the #) and running the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from __future__ import division #Python 2.X and 3.X Compatibility\n",
    "from __future__ import print_function #Python 2.X and 3.X Compatibility\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you didn't have any error so far, you're good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###What is an image anyway?\n",
    "**Short answer** It is just a 2 dimensional array (grayscale image) or a set of Three 2 dimensional arrays (colour image).\n",
    "\n",
    "**Long answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading an Image as a Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = plt.imread('images/macaw.jpg')\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data type and the size of the array $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.shape(A))\n",
    "print(type(A))\n",
    "print(A.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our image is a colour image and it has a resolution of $400 \\times 267$. It is imported as an N-dimenstional array object available from numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us segrigate the **Red**, **Green** and the **Blue** channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_red = A[:, :, 0]\n",
    "A_green = A[:, :, 1]\n",
    "A_blue = A[:, :, 2]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(A_red, cmap=cm.gray) #For a single channel / grayscale image you need to mention the colourmap\n",
    "plt.title('The RED channel')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(A_green, cmap=cm.gray)\n",
    "plt.title('The GREEN channel')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(A_blue, cmap=cm.gray)\n",
    "plt.title('The BLUE channel')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(A_red)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to read and display an image. Let us do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a random uint8 array of size 300x300 with numbers from 0 to 255\n",
    "x = np.random.randint(0, 256, (300, 400)).astype('uint8')\n",
    "plt.imshow(x, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See! A random image! Now let us create a random color image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(0, 256, (300, 400, 3)).astype('uint8')\n",
    "plt.imshow(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Image Enhancement Techniques\n",
    "The principal objective of Image Enhancement is to process an image so that the result is more suitable than the original image for a particular application.\n",
    "\n",
    "However, there are mainly TWO approaches towards image enhancement. A **saptial domain** approach and a **frequency domain** approach.\n",
    "\n",
    "####Spatial Domain Approach\n",
    "It refers to the image plane itself and involves direct manipuation of the pixels of an image.\n",
    "\n",
    "####Frequency Domain Technique\n",
    "Frequency domain processing techniques are based on modifying the Fourier Transform of an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Spatial Domain Approaches\n",
    "Image processing functions in the spatial domain are often of the form $ g(x,y) = \\mathcal{T}[f(x, y)]$, where, $f(x, y)$ is the input image and $g(x, y)$ is the processed output image. $\\mathcal{T}$ is an operation on $f$ defined over some neighbourhood of the pixel at the location $(x, y)$. Usually a neighbourhood of $3\\times 3$ (or sometimes $1\\times 1$) is assumed about the pixel at $(x, y)$.\n",
    "\n",
    "Spatial domain techniques include **Pint processing**, **Image subtraction**, **Spatial filtering**, **Image averaging**, etc.\n",
    "\n",
    "Point processing include **Contrast stretching**, **Gray-level slicing**, **Bit-plane slicing**, **Histogram processing**, etc. \n",
    "\n",
    "Spatial filtering includes **Low pass filtering**, **Median filtering**, **High-pass filtering**, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Histogram and Contrast\n",
    "The word **histogram** in the context of an image simply means a histogram plot of the pixel intensity vs number of pixels.\n",
    "\n",
    "Now, let us go back to the original image of the Macaw. Let us plot the histogram of the pixel intensity. First convert the original image into a grayscale image. This RGB to grayscale conversion would use the formula (more on this formula later)\n",
    "$$X_{Gray} =  [0.299\\quad 0.587\\quad 0.144]  \\cdot \\left[\\begin{array}{c}\n",
    "X_{R}\\\\\n",
    "X_{G}\\\\\n",
    "X_{B}\n",
    "\\end{array}\\right].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image #Python Imaging Library\n",
    "A_gray = Image.open('images/macaw.jpg','r')\n",
    "A_gray = A_gray.convert('L')\n",
    "\n",
    "temp = np.asarray(A_gray.getdata(), dtype=np.float64).reshape((A_gray.size[1], A_gray.size[0]))\n",
    "A_gr = np.asarray(temp, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A_gr, cmap=cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(A_gr.flatten(), 256, range=(0, 255), fc='k', ec='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now narrow the contrast the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Contrast Stretching\n",
    "The possible causes for low contrast images are\n",
    "1. poor illumination\n",
    "2. lack of dynamic range in imaging sensor\n",
    "3. wrong setting of the lens aperture during image acquisition.\n",
    "\n",
    "Contrast stretching attempts to increase the dynamic range of the gray levels of the image being processed. For a neighbourhood of size $1 \\times 1$, contast stretching is usually done by a *gray level transformation* of the form $s = \\mathcal{W}[r]$, where $r$ is the gray level of $f(x, y)$ at $(x, y)$, $s$ is the gray level of $g(x, y)$ at $(x, y)$ and $\\mathcal{W}$ is a graylevel transformation function.\n",
    "\n",
    "Now, let us load a low contrast image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "girl = plt.imread('images/low_contrast.jpg')\n",
    "plt.imshow(girl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(girl.flatten(), 256, range=(0, 255), fc='k', ec='k');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = np.amax(girl)\n",
    "mini = np.amin(girl)\n",
    "intensity_range = maxi - mini\n",
    "print('lowest intensity:', mini, ', highest intensity:', maxi, ', spread:', intensity_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that the image has low contrast, we will use the following transformation function to stretch the contrast of the image. \n",
    "$$s=\\mathcal{W}(r)=\\begin{cases}\n",
    "0, & r<103\\\\\n",
    "\\frac{255}{132}(r-103), & 103\\le r\\le235\\\\\n",
    "255, & r>235\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.arange(0, 256, 1)\n",
    "s = np.zeros(shape(r))\n",
    "s = (255/intensity_range)*(r - mini)\n",
    "s[r<mini] = 0\n",
    "s[r>maxi] = 255\n",
    "\n",
    "plt.plot(r, s)\n",
    "plt.axis([0, 260, -5, 260])\n",
    "xlabel('r')\n",
    "ylabel('s')\n",
    "title('gray-level transformation function $\\mathcal{W}$')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "girl_high = ((girl.astype('float64') - mini) * 255 / intensity_range).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(girl_high, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(girl_high.flatten(), 256, range=(0, 255), fc='k', ec='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that, now the pixel intensities are spread over wider range $[0, 255]$. This is known as linear contrast streatching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Negative\n",
    "If you subtract the pixel intensities of the original image from 255, what you get is essentially the *negative* of the image.\n",
    "$$ X_{neg} = \\left[\\begin{array}{ccc}\n",
    "255 & \\cdots & 255\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "255 & \\cdots & 255\n",
    "\\end{array}\\right]\n",
    " _{m\\times n} - X_{m\\times n}.$$\n",
    " \n",
    " The transformation function in this case looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.arange(0, 256, 1)\n",
    "s = np.zeros(shape(r))\n",
    "s = 255 - r\n",
    "\n",
    "plt.plot(r, s)\n",
    "plt.axis([0, 260, -5, 260])\n",
    "xlabel('r')\n",
    "ylabel('s')\n",
    "title('$\\mathcal{W}$ for finding the negative of an image')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "girl_neg = (255*np.ones(shape(girl_high)) - girl_high).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(girl_neg, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(girl_neg.flatten(), 256, range=(0, 255), fc='k', ec='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the histogram of the negative with that of the original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Dynamic Range Compression\n",
    "\n",
    "*to be done later*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Power Law (Gamma) Transformations / Gamma Corrections\n",
    "Gamma correction involves a nonlinear transformation of the form $s = \\mathcal{W}[r] = 255\\,c\\,\\left(\\dfrac{r}{255}\\right)^\\gamma$, where, $c$ and $\\gamma$ are positive constants. The following plot shows a $r$-vs-$s$ plot for different values of $\\gamma$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1\n",
    "r = np.arange(0, 256)\n",
    "\n",
    "for gamma in [0.04, 0.10, 0.20, 0.40, 0.67, 1, 1.5, 2.5, 5, 10, 25]:\n",
    "    s = 255*c*(r/255)**gamma\n",
    "    plt.plot(r, s)\n",
    "plt.axis([0, 255, 0, 255])\n",
    "plt.xlabel('r')\n",
    "plt.ylabel('s')\n",
    "plt.title('Gamma correction $s = 255\\,c\\,(r/255)^\\gamma$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xray_orig = plt.imread('images/chestxray.jpg')\n",
    "figure(figsize=(20,7))\n",
    "subplot(1, 2, 1)\n",
    "plt.imshow(xray_orig, cmap=cm.gray)\n",
    "plt.title('original')\n",
    "subplot(1, 2, 2)\n",
    "plt.hist(xray_orig.flatten(), 256, range=(2, 255), fc='k', ec='k');\n",
    "\n",
    "c = 1.0\n",
    "gamma = 2.0\n",
    "figure(figsize=(20,7))\n",
    "subplot(1, 2, 1)\n",
    "xray_gamma1 = (255*c*(xray_orig / 255)**gamma).astype('uint8')\n",
    "plt.imshow(xray_gamma1, cmap=cm.gray)\n",
    "plt.title('$c=1.0$, $\\gamma = 2.0$')\n",
    "subplot(1, 2, 2)\n",
    "plt.hist(xray_gamma1.flatten(), 256, range=(2, 255), fc='k', ec='k');\n",
    "\n",
    "c = 1.0\n",
    "gamma = 0.5\n",
    "figure(figsize=(20,7))\n",
    "subplot(1, 2, 1)\n",
    "xray_gamma2 = (255*c*(xray_orig / 255)**gamma).astype('uint8')\n",
    "plt.imshow(xray_gamma2, cmap=cm.gray)\n",
    "plt.title('$c=1.0$, $\\gamma = 0.5$')\n",
    "subplot(1, 2, 2)\n",
    "plt.hist(xray_gamma2.flatten(), 256, range=(2, 255), fc='k', ec='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Gray-level Slicing\n",
    "Sometimes we need to highlight a specific range of gray levels in a image. Possible application areas are *finding masses of water in satellite imagery*, *enhancement of flaws in x-ray images*, etc.\n",
    "\n",
    "There are two basic approaches towards gray-level slicing.\n",
    "1. **Binary Thresholding** : all gray levels in the range of interest are displayed using a high value and the rest using a low value.\n",
    "2. **Gradual Thresholding** : desired range of gray levels are brightened but the background and the gray-level tonalities are preserved.\n",
    "\n",
    "For exaple, let the range of interest be in $[120\\,\\, 180]$. Then the corresponding transformation functions would look like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.arange(0, 256)\n",
    "s = np.zeros(shape(r))\n",
    "s[:] = 200\n",
    "s[r<120] = 10\n",
    "s[r>180] = 10\n",
    "plt.subplot(1, 2, 1)\n",
    "plot(r, s)\n",
    "plt.axis([0, 255, 0, 255])\n",
    "plt.title('Binary thresholding function')\n",
    "\n",
    "r = np.arange(0, 256)\n",
    "s = np.arange(0, 256)\n",
    "a = r>120\n",
    "b = r<180\n",
    "s[a * b] = 200\n",
    "plt.subplot(1, 2, 2)\n",
    "plot(r, s)\n",
    "plt.axis([0, 255, 0, 255])\n",
    "plt.title('Gradual thresholding function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let us use these ideas in real life!\n",
    "\n",
    "Load Scikit-image. It has built-in image data sets. More at http://scikit-image.org/docs/dev/api/skimage.data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "scanned = data.page()\n",
    "plt.imshow(scanned, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(scanned.flatten(), 256, range=(0, 255), fc='k', ec='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By means of visual inspection we find that the texts in the scanned page has intensity values higher than $150$ and the background has intensity values lower than that. \n",
    "\n",
    "(N.B. This is a very crude method! We will automate this later.)\n",
    "\n",
    "So, we would consider a thresholding function that will search the image pixel by pixel. If the intensity of a pixel is greater than or equal to 150, it will be assigned a value of 255 and if its intensity falls below 150, a zero will be assigned in its place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = np.zeros(shape(scanned)).astype('uint8')\n",
    "threshold = 150\n",
    "thres[scanned<threshold] = 0\n",
    "thres[scanned>=threshold] = 255\n",
    "plt.imshow(thres, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the value of the threshold in the above programme and see the changes!\n",
    "\n",
    "Now consider gradual thresholding. We consider that the region of interest lies between intensity values of 100 and 170."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres1 = copy(scanned)\n",
    "threshold_hi = 170\n",
    "threshold_lo = 100\n",
    "thres1[scanned<threshold_lo] = 0\n",
    "thres1[scanned>threshold_hi] = 255\n",
    "plt.imshow(thres1, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####Bit Plane Slicing\n",
    "1. Sometimes it is desirable to highlight the contribution made by specific bits to the total image appearance.\n",
    "2. The image can be imagined to be composed of Eight 1-bit planes -- Plane 0 for the LSB plane and Plane 7 for the MSB.\n",
    "3. The higher order bits contain visually significant data, the lower order plane contain more subtle details.\n",
    "\n",
    "This can be acomplished by doing a **Bitwise AND** operation. For example, say the intensity of a pixel is 246 in decimal. In binary this would be $(1111\\,0110)_2$. So in order to find the value of the 6th bit, one has to siimply do this $(1111\\,0110)_2 \\odot  (0100\\,0000)_2$. The result will simply produce the value of the 6th bit. In other words, $246 \\odot 64$ will give you the value of the 6th bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane7 = A_gr & 128*np.ones(shape(A_gr)).astype('uint8')\n",
    "plane6 = A_gr &  64*np.ones(shape(A_gr)).astype('uint8')\n",
    "plane5 = A_gr &  32*np.ones(shape(A_gr)).astype('uint8')\n",
    "plane4 = A_gr &  16*np.ones(shape(A_gr)).astype('uint8')\n",
    "plane3 = A_gr &   8*np.ones(shape(A_gr)).astype('uint8')\n",
    "plane2 = A_gr &   4*np.ones(shape(A_gr)).astype('uint8')\n",
    "plane1 = A_gr &   2*np.ones(shape(A_gr)).astype('uint8')\n",
    "plane0 = A_gr &   1*np.ones(shape(A_gr)).astype('uint8')\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(2, 4, 1)\n",
    "plt.imshow(plane7, cmap=cm.gray)\n",
    "plt.title('Plane 7 (MSB)')\n",
    "plt.subplot(2, 4, 2)\n",
    "plt.imshow(plane6, cmap=cm.gray)\n",
    "plt.title('Plane 6')\n",
    "plt.subplot(2, 4, 3)\n",
    "plt.imshow(plane5, cmap=cm.gray)\n",
    "plt.title('Plane 5')\n",
    "plt.subplot(2, 4, 4)\n",
    "plt.imshow(plane4, cmap=cm.gray)\n",
    "plt.title('Plane 4')\n",
    "plt.subplot(2, 4, 5)\n",
    "plt.imshow(plane3, cmap=cm.gray)\n",
    "plt.title('Plane 3')\n",
    "plt.subplot(2, 4, 6)\n",
    "plt.imshow(plane2, cmap=cm.gray)\n",
    "plt.title('Plane 2')\n",
    "plt.subplot(2, 4, 7)\n",
    "plt.imshow(plane1, cmap=cm.gray)\n",
    "plt.title('Plane 1')\n",
    "plt.subplot(2, 4, 8)\n",
    "plt.imshow(plane0, cmap=cm.gray)\n",
    "plt.title('Plane 0 (LSB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Spatial Filtering\n",
    "**Low pass filters** attenuate or eliminate high frequncy components in the Fourier domain. Low pass filtering gives rise to image blurring.\n",
    "\n",
    "**High pass filters** attenuate or eliminate low frequncy components in the Fourier domain. High pass filtering gives rise to sharpening of edges and other sharp details.\n",
    "####How to implement?\n",
    "Utilize suitable **2D** masks of suitable size, e.g. $3 \\times 3$, $5 \\times 5$ or $7 \\times 7$.\n",
    "In most of our use cases, we shall restrict ourselves to $3 \\times 3$ masks. The mask is applied to certain pixels. Upon application, the mask calculates a wighted sum of the neighbourhood of the concerned pixel and the result substitutes the original pixel. Here is how it works.\n",
    "\n",
    "Consider that there is a pixel of intensity $z_5$. The $3 \\times 3$ neighbourhood of the pixel can be seen as $$\\left[\\begin{array}{ccc}\n",
    "z_{1} & z_{2} & z_{3}\\\\\n",
    "z_{4} & z_{5} & z_{6}\\\\\n",
    "z_{7} & z_{8} & z_{9}\n",
    "\\end{array}\\right].$$\n",
    "Now consider that the mask that is applied on the pixel with intensity $z_5$ looks like $$\\left[\\begin{array}{ccc}\n",
    "w_{1} & w_{2} & w_{3}\\\\\n",
    "w_{4} & w_{5} & w_{6}\\\\\n",
    "w_{7} & w_{8} & w_{9}\n",
    "\\end{array}\\right].$$\n",
    "\n",
    "Then, it will substitute $z_5$ by $w_1 z_1 + w_2 z_2 + \\cdots + w_9 z_9$. Thus, $$z_{5\\{new\\}}=\\sum_{i=1}^9 w_i z_i.$$\n",
    "\n",
    "Thus, \n",
    "$$\\left[\\begin{array}{ccc}\n",
    "z_{1} & z_{2} & z_{3}\\\\\n",
    "z_{4} & z_{5} & z_{6}\\\\\n",
    "z_{7} & z_{8} & z_{9}\n",
    "\\end{array}\\right] \\otimes\n",
    "\\left[\\begin{array}{ccc}\n",
    "w_{1} & w_{2} & w_{3}\\\\\n",
    "w_{4} & w_{5} & w_{6}\\\\\n",
    "w_{7} & w_{8} & w_{9}\n",
    "\\end{array}\\right] = \n",
    "\\left[\\begin{array}{ccc}\n",
    "z_{1} & z_{2} & z_{3}\\\\\n",
    "z_{4} & \\sum_{i=1}^9 w_i z_i & z_{6}\\\\\n",
    "z_{7} & z_{8} & z_{9}\n",
    "\\end{array}\\right].$$\n",
    "\n",
    "It does not do any changes to any other pixel anyway. The mask is centred on the image pixel whose new intensity value is tobe calculated. This calculation is performed for each pixel seperately by moving the mask to centre it on the pixel under consideration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Smoothig spatial filters\n",
    "####Low pass spatial filtering\n",
    "Examples of low pass spatial filter masks are\n",
    "\n",
    "$$\\mathcal{L}_1 = \\dfrac{1}{9}\\left[\\begin{array}{ccc}\n",
    "1 & 1 & 1\\\\\n",
    "1 & 1 & 1\\\\\n",
    "1 & 1 & 1\n",
    "\\end{array}\\right]; \\quad\\quad\n",
    "\\mathcal{L}_2 = \\dfrac{1}{16}\\left[\\begin{array}{ccc}\n",
    "1 & 2 & 1\\\\\n",
    "2 & 4 & 2\\\\\n",
    "1 & 2 & 1\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "1. A low pass filter must have all positive coefficients.\n",
    "2. For a low pass spatial filter mask shown as $\\mathcal{L}_1$, the operation is also popularly termed as neighbourhood averaging. This averaging causes blurring and loss of sharpness.\n",
    "3. For a filter mask shown in $\\mathcal{L}_2$, it is called weighted averaging. \n",
    "\n",
    "####Median filtering\n",
    "Median filters are **nonlinear** (why?) filters employed with an objective of noise reduction, withot bluring.\n",
    "\n",
    "$$\\underset{\\textrm{image section under consideration}}{\\underbrace{\\left[\\begin{array}{ccc}\n",
    "z_{1} & z_{2} & z_{3}\\\\\n",
    "z_{4} & z_{5} & z_{6}\\\\\n",
    "z_{7} & z_{8} & z_{9}\n",
    "\\end{array}\\right]}} \\underset{\\textrm{median filtering}}{\\Rightarrow} \n",
    "\\underset{\\textrm{result of median filtering}}{\\underbrace{\\left[\\begin{array}{ccc}\n",
    "z_{1} & z_{2} & z_{3}\\\\\n",
    "z_{4} & \\textrm{med}\\{z_{5}\\} & z_{6}\\\\\n",
    "z_{7} & z_{8} & z_{9}\n",
    "\\end{array}\\right]}},$$\n",
    "where $\\textrm{med}\\{z_{5}\\}$ is the median of $z_1, z_2, \\cdots, z_9$. Median value can be easily calculated by arranging $z_1, z_2, \\cdots, z_9$ in ascending order of maginitude and then finding the value that is in the middle position.\n",
    "\n",
    "This filter is most effective when the noise pattern consists of niose-like components and it is of utmost importance to preserve edge sharpness. \n",
    "\n",
    "Now we shall use **scikit-image**. There are many built in filters. Check http://scikit-image.org/docs/stable/api/skimage.filters.html for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean filtering\n",
    "from scipy import ndimage\n",
    "lena_noisy = plt.imread('images/lena_noisy.png')\n",
    "mask1 = (1/9)*np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) #LP mask\n",
    "mask2 = (1/16)*np.array([[1, 2, 1], [2, 1, 2], [1, 2, 1]]) #LP mask\n",
    "result1 = ndimage.convolve(lena_noisy, mask1, mode='constant', cval=0.0)\n",
    "result2 = ndimage.convolve(lena_noisy, mask2, mode='constant', cval=0.0)\n",
    "figure(figsize=(15, 5))\n",
    "subplot(1, 3, 1)\n",
    "imshow(lena_noisy, cmap=cm.gray)\n",
    "title('Original')\n",
    "subplot(1, 3, 2)\n",
    "imshow(result1, cmap=cm.gray)\n",
    "title('Filtered with LP mask $\\mathcal{L}_1$')\n",
    "subplot(1, 3, 3)\n",
    "imshow(result2, cmap=cm.gray)\n",
    "title('Filtered with LP mask $\\mathcal{L}_2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that the low pass filter significantly reduces the noise level.\n",
    "\n",
    "Now let us apply median filtering to the same image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import disk #needed for the mask\n",
    "from skimage.filters.rank import median\n",
    "lena_med = median(lena_noisy, disk(3))\n",
    "figure(figsize=(10, 5))\n",
    "subplot(1, 2, 1)\n",
    "imshow(lena_noisy, cmap=cm.gray)\n",
    "title('Original')\n",
    "subplot(1, 2, 2)\n",
    "imshow(lena_med, cmap=cm.gray)\n",
    "title('Median filtering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can easily see, an image corrupted with **speckle noise** can be better denoised with mean filtering. Now check an image with **salt and pepper noise**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt = plt.imread('images/saltandpepper.jpg')\n",
    "mask = (1/9)*np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\n",
    "salt_lp = ndimage.convolve(salt, mask, mode='constant', cval=0.0)\n",
    "salt_med = median(salt, disk(2))\n",
    "figure(figsize=(15, 5))\n",
    "subplot(1, 3, 1)\n",
    "imshow(salt, cmap=cm.gray)\n",
    "title('Original')\n",
    "subplot(1, 3, 2)\n",
    "imshow(salt_lp, cmap=cm.gray)\n",
    "title('Filtered with LP mask $\\mathcal{L}_1$')\n",
    "subplot(1, 3, 3)\n",
    "imshow(salt_med, cmap=cm.gray)\n",
    "title('Median filtering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Sharpening spatial filters\n",
    "####Derivative filters\n",
    "1. The differentiation operation is expected to sharpen an image.\n",
    "2. One can use either first derivative or second derivative information.\n",
    "\n",
    "**Digital approximation of first derivative** : $\\dfrac{\\partial f(x,y)}{\\partial x} = f(x+1, y) - f(x, y), $ and $\\dfrac{\\partial f(x,y)}{\\partial y} = f(x, y+1) - f(x, y).$\n",
    "\n",
    "*Constraints* : The response of a first derivative filter must be\n",
    "1. zero in areas of constant intensity,\n",
    "2. must be non-zero at the onset of an intensity step or ramp,\n",
    "3. nonzero along ramps.\n",
    "\n",
    "**Digital approximation of second derivative** : $\\dfrac{\\partial ^2f(x,y)}{\\partial x^2} = f(x+1, y) - 2 f(x, y) +f(x-1, y),$ and $\\dfrac{\\partial ^2f(x,y)}{\\partial y^2} = f(x, y+1) - 2 f(x, y) +f(x, y-1).$\n",
    "\n",
    "*Constraints* : The response of a second order derivative filter must be\n",
    "1. zero in areas of constant intensity,\n",
    "2. non-zero at the onset and the end of an intensity step or ramp,\n",
    "3. zero along ramps of constant slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Implementing a first derivative filter for image sharpening\n",
    "A first derivative image sharpening filter can be implemented by by applying the Gradient function. The gradient of a function $f(x, y)$ at coordinates $(x, y)$ is defined as the **2D** column vector \n",
    "\n",
    "$$\\nabla f(x,y)\\equiv\\mathrm{grad}(f)\\equiv \\mathbf{g} \\equiv \\left[\\begin{array}{c}\n",
    "g_{x}(x,y)\\\\\n",
    "g_{y}(x,y)\n",
    "\\end{array}\\right]=\\left[\\begin{array}{c}\n",
    "\\frac{\\partial f(x,y)}{\\partial x}\\\\\n",
    "\\frac{\\partial f(x,y)}{\\partial y}\n",
    "\\end{array}\\right].$$\n",
    "\n",
    "The magnitude (length) of vector $\\nabla f$ is given by $M(x, y) = ||\\nabla f||= \\sqrt{\\mathbf{g}^T \\mathbf{g}} = \\sqrt{g_x^2 + g_y^2}$. In image processing, this last expression is often approximated as $|g_x| + |g_y|$.\n",
    "\n",
    "$M(x, y)$ is an image of the same size of the original and called the **gradient image**. The computation of this gradient is the basis of various approaches to develop first derivative filter. \n",
    "\n",
    "If $$\\left[\\begin{array}{ccc}\n",
    "z_{1} & z_{2} & z_{3}\\\\\n",
    "z_{4} & z_{5} & z_{6}\\\\\n",
    "z_{7} & z_{8} & z_{9}\n",
    "\\end{array}\\right]$$ \n",
    "\n",
    "is the image section under consideration, then, according to the above theory, after the application of first derivative filtering, the new value of $z_5$ will be $$M(x,y) = [(z_8 - z_5)^2 + (z_6 - z_5)^2]^{1/2} \\approx |z_8 - z_5| + |z_6 - z_5|.$$ Another implementation involves cross-differences: $$M(x,y) = [(z_9 - z_5)^2 + (z_8 - z_6)^2]^{1/2} \\approx |z_9 - z_5| + |z_8 - z_6|.$$ But there is one problem : masks of **even** size are awkward to implement (why?). Hence an approximation with $3 \\times 3$ neighbourhood is preferred. The mostly used first order derivative masks are Sobel masks and Prewitt masks. They are like follows : \n",
    "\n",
    "$$\\mathcal{S}_{y}=\\underset{\\textrm{Sobel horizontal derivative}}{\\underbrace{\\left[\\begin{array}{ccc}\n",
    "-1 & -2 & -1\\\\\n",
    "0 & 0 & 0\\\\\n",
    "1 & 2 & 1\n",
    "\\end{array}\\right]}}; \\quad\n",
    "\\mathcal{S}_{x}=\\underset{\\textrm{Sobel vertical derivative}}{\\underbrace{\\left[\\begin{array}{ccc}\n",
    "-1 & 0 & 1\\\\\n",
    "-2 & 0 & 2\\\\\n",
    "-1 & 0 & 1\n",
    "\\end{array}\\right]}}; \\quad\n",
    "\\mathcal{P}_{y}=\\underset{\\textrm{Prewitt horizontal derivative}}{\\underbrace{\\left[\\begin{array}{ccc}\n",
    "-1 & -1 & -1\\\\\n",
    "0 & 0 & 0\\\\\n",
    "1 & 1 & 1\n",
    "\\end{array}\\right]}}; \\quad\n",
    "\\mathcal{P}_{x}=\\underset{\\textrm{Prewitt vertical derivative}}{\\underbrace{\\left[\\begin{array}{ccc}\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\n",
    "\\end{array}\\right]}}\n",
    ".$$\n",
    "Now, lets get to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters, data\n",
    "camera = data.camera()\n",
    "\n",
    "#apply sobel gradient\n",
    "sobel_camera = filters.sobel(camera)\n",
    "\n",
    "#apply prewitt gradient\n",
    "prewitt_camera = filters.prewitt(camera)\n",
    "\n",
    "figure(figsize=(15, 5))\n",
    "subplot(1, 3, 1)\n",
    "imshow(camera, cmap=cm.gray)\n",
    "title('Original')\n",
    "subplot(1, 3, 2)\n",
    "imshow(sobel_camera, cmap=cm.gray)\n",
    "title('Result of a Sobel gradient')\n",
    "subplot(1, 3, 3)\n",
    "imshow(prewitt_camera, cmap=cm.gray)\n",
    "title('Result of a Prewitt Gradient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters, data\n",
    "xray = plt.imread('images/chestxray.jpg')\n",
    "\n",
    "#apply sobel gradient\n",
    "sobel_xray = filters.sobel(xray)\n",
    "\n",
    "#apply prewitt gradient\n",
    "prewitt_xray = filters.prewitt(xray)\n",
    "\n",
    "figure(figsize=(15, 5))\n",
    "subplot(1, 3, 1)\n",
    "imshow(xray, cmap=cm.gray)\n",
    "title('Original')\n",
    "subplot(1, 3, 2)\n",
    "imshow(sobel_xray, cmap=cm.gray)\n",
    "title('Result of a Sobel gradient')\n",
    "subplot(1, 3, 3)\n",
    "imshow(prewitt_xray, cmap=cm.gray)\n",
    "title('Result of a Prewitt Gradient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Laplacian filter\n",
    "A second order derivative filter can be implemented by employing a Laplacian mask. The Laplacian of an image function $f(x, y)$ of two variables is defined as $\\nabla ^2 f(x, y) = \\dfrac{\\partial ^2f(x,y)}{\\partial x^2} + \\dfrac{\\partial ^2f(x,y)}{\\partial y^2}.$ \n",
    "\n",
    "Thus, $\\nabla ^2 f(x, y) = f(x+1, y) + f(x-1, y) + f(x, y+1) + f(x, y-1) - 4f(x,y)$.\n",
    "So, a Laplacian mask would look like\n",
    "\n",
    "$$\\nabla^2_\\perp=\\underset{\\textrm{Laplacian mask}}{\\underbrace{\\left[\\begin{array}{rrr}\n",
    "0 & 1 & 0\\\\\n",
    "1 & -4 & 1\\\\\n",
    "0 & 1 & 0\n",
    "\\end{array}\\right]}}; \\quad\n",
    "\\nabla^2_\\odot=\\underset{\\textrm{Omnidirectional Laplacian mask}}{\\underbrace{\\left[\\begin{array}{rrr}\n",
    "1 & 1 & 1\\\\\n",
    "1 & -8 & 1\\\\\n",
    "1 & 1 & 1\n",
    "\\end{array}\\right]}}.$$\n",
    "The second one, here, considers four directions 1. horizontal, 2. vertical, 3. +45$^\\circ$ and 4. -45$^\\circ$, whereas, the first one only considers the horizontal and vertical directions.\n",
    "\n",
    "However, there is a problem regarding the direct implementation of a Laplacian mask. Being a second derivative operation, it highlights intensity discontinuities in an image, and in the process de-emphasizes image regions having slow variations in intensity profile. SO, in order to preserve the original background features and yet perform sharpening operation, the Laplacian operator is utilized in the following manner:\n",
    "$$g(x,y) = f(x, y) + c\\left[\\nabla^2 f(x, y)\\right],$$ where, $c=-1$ for the operators we considered.\n",
    "\n",
    "Here is a comparison of Laplacian filter with Sobel filters. For the first time, we are going to use OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #this is OpenCV\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('images/dave.jpg',0) #import the image as grayscale\n",
    "\n",
    "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
    "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')\n",
    "plt.title('Laplacian')\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(sobelx,cmap = 'gray')\n",
    "plt.title('Sobel X')\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(sobely,cmap = 'gray')\n",
    "plt.title('Sobel Y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use Scikit-image to achieve the same goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import img_as_ubyte, img_as_int\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "moon = cv2.imread('images/blurry_moon.jpg',0)\n",
    "img = img_as_int(moon)\n",
    "laplacian1 = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype='float64')  #Laplacian 1 mask\n",
    "laplacian2 = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype='float64') / 3.0 #Laplacian 2 mask\n",
    "sobelx = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype='float64') / 4.0 #Sobel x mask\n",
    "sobely = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype='float64') / 4.0 #Sobel y mask\n",
    "\n",
    "out_laplacian1 = img_as_ubyte(ndimage.convolve(img, laplacian1, mode='constant', cval=0.0))\n",
    "out_laplacian2 = img_as_ubyte(ndimage.convolve(img, laplacian2, mode='constant', cval=0.0))\n",
    "out_sobelx = img_as_ubyte(ndimage.convolve(img, sobelx, mode='constant', cval=0.0))\n",
    "out_sobely = img_as_ubyte(ndimage.convolve(img, sobely, mode='constant', cval=0.0))\n",
    "img_out_laplacian1 = img_as_ubyte(img - out_laplacian1)\n",
    "img_out_laplacian2 = img_as_ubyte(img - out_laplacian2)\n",
    "img_out_sobelx = img_as_ubyte(img - out_sobelx)\n",
    "img_out_sobely = img_as_ubyte(img - out_sobely)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(3,3,1)\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "plt.subplot(3,3,2)\n",
    "plt.imshow(out_laplacian2, cmap = 'gray')\n",
    "plt.title('Laplacian 1')\n",
    "plt.subplot(3,3,3)\n",
    "plt.imshow(out_laplacian2, cmap = 'gray')\n",
    "plt.title('Laplacian 2')\n",
    "plt.subplot(3,3,4)\n",
    "plt.imshow(out_sobelx, cmap = 'gray')\n",
    "plt.title('Sobel X')\n",
    "plt.subplot(3,3,5)\n",
    "plt.imshow(out_sobely, cmap = 'gray')\n",
    "plt.title('Sobel Y')\n",
    "plt.subplot(3,3,6)\n",
    "plt.imshow(img_out_laplacian1, cmap = 'gray')\n",
    "plt.title('Original - Laplacian 1')\n",
    "plt.subplot(3,3,7)\n",
    "plt.imshow(img_out_laplacian2, cmap = 'gray')\n",
    "plt.title('Original - Laplacian 2')\n",
    "plt.subplot(3,3,8)\n",
    "plt.imshow(img_out_sobelx, cmap = 'gray')\n",
    "plt.title('Original - Sobel X')\n",
    "plt.subplot(3,3,9)\n",
    "plt.imshow(img_out_sobely, cmap = 'gray')\n",
    "plt.title('Original - Sobel Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, check out Python Imaging Library (fork: pillow). It contains many built in spatial filter modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "    \n",
    "im0 = Image.open('images/blurry_moon.jpg')\n",
    "\n",
    "figure(figsize=(15,15))\n",
    "subplot(3,4,1)\n",
    "plt.imshow(im0)\n",
    "plt.title('Original')\n",
    "subplot(3,4,2)\n",
    "im2 = im0.filter(ImageFilter.CONTOUR)\n",
    "plt.imshow(im2)\n",
    "plt.title('Contour')\n",
    "subplot(3,4,3)\n",
    "im3 = im0.filter(ImageFilter.DETAIL) \n",
    "plt.imshow(im3)\n",
    "plt.title('Detail')\n",
    "subplot(3,4,4)\n",
    "im4 = im0.filter(ImageFilter.EDGE_ENHANCE) \n",
    "plt.imshow(im4)\n",
    "plt.title('Laplacian 1')\n",
    "subplot(3,4,5)\n",
    "im5 = im0.filter(ImageFilter.EDGE_ENHANCE_MORE)  \n",
    "plt.imshow(im5)\n",
    "plt.title('Laplacian 2')\n",
    "subplot(3,4,6)\n",
    "im6 = im0.filter(ImageFilter.EMBOSS)  \n",
    "plt.imshow(im6)\n",
    "plt.title('Emboss')\n",
    "subplot(3,4,7)\n",
    "im7 = im0.filter(ImageFilter.FIND_EDGES)\n",
    "plt.imshow(im7)\n",
    "plt.title('Sobel')\n",
    "subplot(3,4,8)\n",
    "im8 = im0.filter(ImageFilter.SMOOTH)  \n",
    "plt.imshow(im8)\n",
    "plt.title('Low Pass 1')\n",
    "subplot(3,4,9)\n",
    "im9 = im0.filter(ImageFilter.SMOOTH_MORE) \n",
    "plt.imshow(im9)\n",
    "plt.title('Low Pass 2')\n",
    "subplot(3,4,10)\n",
    "im10 = im0.filter(ImageFilter.SHARPEN)\n",
    "plt.imshow(im10)\n",
    "plt.title('Sharpen')\n",
    "subplot(3,4,10)\n",
    "im1 = im0.filter(ImageFilter.BLUR)\n",
    "plt.imshow(im1)\n",
    "plt.title('Blur')\n",
    "\n",
    "#Custom mask\n",
    "\n",
    "size = (3, 3)\n",
    "kernel1 = [1, 1, 1, 0, 0, 0, -1, -1, -1]\n",
    "ker1 = ImageFilter.Kernel(size, kernel1, scale=None, offset=0)\n",
    "subplot(3,4,11)\n",
    "im11 = im0.filter(ker1)\n",
    "plt.imshow(im11)\n",
    "plt.title('Custom 1')\n",
    "\n",
    "kernel2 = [1, 0, -1, 1, 0, -1, 0, 0, -1]\n",
    "ker2 = ImageFilter.Kernel(size, kernel2, scale=None, offset=0)\n",
    "subplot(3,4,12)\n",
    "im12 = im0.filter(ker2)\n",
    "plt.imshow(im12)\n",
    "plt.title('Custom 2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**An important point to note** : For a high pass spatial filter mask , whether utilizing first derivative or second derivative, the sum of the mask coefficients is always zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Unsharp masking and high boost filtering\n",
    "This approach sharpens an image using kind of a 'back-calculation' method! Let the original image function be $f(x, y)$. First, a blurred version of the image is created. Let this version be $\\bar{f}(x,y)$. Then this blurred version is subtracted from the original image. This creates a mask like $g_{mask}(x,y) = f(x, y) - \\bar{f}(x,y)$. Then this mask is added to the original image resulting $g(x,y) = f(x,y) + k\\,g_{mask}(x,y)$, where, $k$ is a constant. \n",
    "\n",
    "If $k=1$, this process is called **unsharp masking**. When $k>1$, it is called **high boost filtering**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage import img_as_ubyte, img_as_int\n",
    "from scipy import ndimage\n",
    "\n",
    "coins = img_as_int(data.coins())\n",
    "low_pass = (1/9)*np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]], dtype='float64') #LP mask\n",
    "blurred = ndimage.convolve(coins, low_pass, mode='constant', cval=0.0)\n",
    "unsharp_mask = img_as_ubyte(coins - blurred)\n",
    "k = 1\n",
    "sharpened = img_as_ubyte(coins + k*unsharp_mask)\n",
    "\n",
    "figure(figsize=(15,5))\n",
    "subplot(1, 3, 1)\n",
    "title('Original')\n",
    "imshow(coins, cmap=cm.gray)\n",
    "subplot(1, 3, 2)\n",
    "title('Unsharp mask')\n",
    "imshow(unsharp_mask, cmap=cm.gray)\n",
    "subplot(1, 3, 3)\n",
    "title('Unsharp masked image')\n",
    "imshow(sharpened, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Frequency Domain Approaches\n",
    "Once we are comfortable with the spatial domain image enhancement techniques described above, we are ready to jump into a completely different approach towards image processing. Instead of directly manipulating the pixels in an image, we will now manipulate the **Fourier Transform** of the image. We would utilize the concept of ***2D*** **Discrete Fourier Transform (DFT)**, **Fast Fourier Transform (FFT)** and the Convolution theorem in 2 dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2D DFT pair for an image function $f(x,y)$ can be expressed as $$F(u, v) = \\frac{1}{MN} \\sum _{x=0}^{M-1} \\sum _{y=0}^{N-1} f(x,y) \\exp\\left[-j2\\pi\\left(\\frac{ux}{M}+\\frac{vy}{N}\\right)\\right],$$ for $x=0,1,\\cdots,M-1$ and $y=0,1,\\cdots,N-1$, and \n",
    "$$f(x,y) =\\sum _{u=0}^{M-1} \\sum _{v=0}^{N-1} f(x,y) \\exp\\left[j2\\pi\\left(\\frac{ux}{M}+\\frac{vy}{N}\\right)\\right],$$ for $u=0,1,\\cdots,M-1$ and $v=0,1,\\cdots,N-1$.\n",
    "\n",
    "The convolution theorem in 2D states that, $$h(x,y)* f(x,y) \\rightleftharpoons H(u,v)F(u,v),$$ and $$ H(u,v)*F(u,v) \\rightleftharpoons h(x,y)f(x,y).$$\n",
    "\n",
    "In image enhancement problems, $f(x,y)$ is the input image, $g(x,y)$ is the output image and it is obtained by the application of a linear position invariant operator $h(x,y)$ on $f(x,y)$. Thus, $g(x,y)=h(x,y)* f(x,y),$ and $G(u,v)=H(u,v)* F(u,v)$. Here, $G(u,v)$, $H(u,v)$, and $F(u,v)$ are the DFTs of $g(x,y)$, $h(x,y)$ and $f(x,y)$ respectively. $H(u,v)$ is often called the **process transfer function**.\n",
    "\n",
    "The main goal in frequency domain approach in image enhancement is to select a suitable $H(u,v)$ such that $g(x,y)$ exhibit some highlighted feature of $f(x,y)$.\n",
    "\n",
    "Image processing in frequency domain usually involves the following steps:\n",
    "\n",
    "INPUT : $f(x,y)$\n",
    "1. Preprocess the input image $f(x,y)$\n",
    "2. Take its DFT or FFT\n",
    "3. Multiply the result with a suitable process transfer function $H$\n",
    "4. Take the IDFT or IFFT of the result\n",
    "5. Do some post-processing\n",
    "\n",
    "OUTPUT : Enhanced image $g(x,y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, \n",
    "for Low Pass filtering one can using the Gaussian LPF TRansfer Function \n",
    "$$H_{GLPF}(u,v)=\\exp\\left[-\\frac{D(u,v)}{2\\sigma^2}\\right],$$\n",
    "and for High Pass filtering, one can use this:\n",
    "$$H_{GHPF}(u,v)=1-\\exp\\left[-\\frac{D(u,v)}{2\\sigma^2}\\right].$$\n",
    "Here, $D(u,v)$ is the distance of the point $(u,v)$ from the origin of the frequency plane, and $\\sigma$ (std. deviation) is a measure of the spread of the Gaussian curve.\n",
    "\n",
    "One can apply this to an image simply by using a built-in module in `skimage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage.filters import gaussian_filter\n",
    "image = data.coins()\n",
    "lpgf_img = gaussian_filter(image, sigma=2, multichannel=True)\n",
    "hpgf_img = image - lpgf_img\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "plt.title('Input Image')\n",
    "plt.subplot(132)\n",
    "plt.imshow(lpgf_img, cmap = 'gray')\n",
    "plt.title('LPGF with $\\sigma=2$')\n",
    "plt.subplot(133)\n",
    "plt.imshow(hpgf_img, cmap = 'gray')\n",
    "plt.title('HPGF with $\\sigma=2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we will see how to find Fourier Transform using Numpy. Numpy has an FFT package to do this. `np.fft.fft2()` provides us the frequency transform which will be a complex array. Its first argument is the input image, which is grayscale. Second argument is optional which decides the size of output array. If it is greater than size of input image, input image is padded with zeros before calculation of FFT. If it is less than input image, input image will be cropped. If no arguments passed, Output array size will be same as input.\n",
    "\n",
    "Now once you got the result, zero frequency component (DC component) will be at top left corner. If you want to bring it to center, you need to shift the result by $\\frac{N}{2}$ in both the directions. This is simply done by the function, `np.fft.fftshift()`. (It is more easier to analyze). Once you found the frequency transform, you can find the magnitude spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('images/blurry_moon.jpg',0)\n",
    "f = np.fft.fft2(img)\n",
    "fshift = np.fft.fftshift(f)\n",
    "magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Input Image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
    "plt.title('Magnitude Spectrum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See, You can see more whiter region at the center showing low frequency content is more.\n",
    "\n",
    "So you found the frequency transform Now you can do some operations in frequency domain, like high pass filtering and reconstruct the image, ie find inverse DFT. For that you simply remove the low frequencies by masking with a rectangular window of size $60\\times 60$. Then apply the inverse shift using `np.fft.ifftshift()` so that DC component again come at the top-left corner. Then find inverse FFT using `np.ifft2()` function. The result, again, will be a complex number. You can take its absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = img.shape\n",
    "crow,ccol = rows/2 , cols/2\n",
    "fshift[crow-30:crow+30, ccol-30:ccol+30] = 0\n",
    "f_ishift = np.fft.ifftshift(fshift)\n",
    "img_back = np.fft.ifft2(f_ishift)\n",
    "img_back = np.abs(img_back)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131),plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Input Image')\n",
    "plt.subplot(132),plt.imshow(img_back, cmap = 'gray')\n",
    "plt.title('Image after HPF')\n",
    "plt.subplot(133),plt.imshow(img_back)\n",
    "plt.title('Result in JET')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shows High Pass Filtering is an edge detection operation. This also shows that most of the image data is present in the Low frequency region of the spectrum. Anyway we have seen how to find DFT, IDFT etc in Numpy. Now let’s see how to do it in OpenCV.\n",
    "\n",
    "If you closely watch the result, especially the last image in JET color, you can see some artifacts. It shows some ripple like structures there, and it is called ringing effects. It is caused by the rectangular window we used for masking. This mask is converted to sinc shape which causes this problem. So rectangular windows is not used for filtering. Better option is Gaussian Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Fourier Transform in OpenCV\n",
    "\n",
    "OpenCV provides the functions `cv2.dft()` and `cv2.idft()` for this. It returns the same result as previous, but with two channels. First channel will have the real part of the result and second channel will have the imaginary part of the result. The input image should be converted to np.float32 first. We will see how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('images/blurry_moon.jpg',0)\n",
    "\n",
    "dft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "magnitude_spectrum = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Input Image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
    "plt.title('Magnitude Spectrum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have to do inverse DFT. In previous session, we created a HPF, this time we will see how to remove high frequency contents in the image, ie we apply LPF to image. It actually blurs the image. For this, we create a mask first with high value (1) at low frequencies, ie we pass the LF content, and 0 at HF region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = img.shape\n",
    "crow,ccol = rows/2 , cols/2\n",
    "\n",
    "# create a mask first, center square is 1, remaining all zeros\n",
    "mask = np.zeros((rows,cols,2),np.uint8)\n",
    "mask[crow-30:crow+30, ccol-30:ccol+30] = 1\n",
    "\n",
    "# apply mask and inverse DFT\n",
    "fshift = dft_shift*mask\n",
    "f_ishift = np.fft.ifftshift(fshift)\n",
    "img_back = cv2.idft(f_ishift)\n",
    "img_back = cv2.magnitude(img_back[:,:,0],img_back[:,:,1])\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121),plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Input Image')\n",
    "plt.subplot(122),plt.imshow(img_back, cmap = 'gray')\n",
    "plt.title('LPF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** :  As usual, OpenCV functions `cv2.dft()` and `cv2.idft()` are faster than Numpy counterparts. But Numpy functions are more user-friendly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Why Laplacian is a High Pass Filter?\n",
    "The question is, why Laplacian is a high pass filter? Why Sobel is a HPF? etc. And the simplest answer that can be given to it is in terms of Fourier Transform. Just take the fourier transform of Laplacian for some higher size of FFT. Analyze it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# simple averaging filter without scaling parameter\n",
    "mean_filter = np.ones((3,3))\n",
    "\n",
    "# creating a guassian filter\n",
    "x = cv2.getGaussianKernel(5,10)\n",
    "gaussian = x*x.T\n",
    "\n",
    "# different edge detecting filters\n",
    "# scharr in x-direction\n",
    "scharr = np.array([[-3, 0, 3],\n",
    "                   [-10,0,10],\n",
    "                   [-3, 0, 3]])\n",
    "# sobel in x direction\n",
    "sobel_x= np.array([[-1, 0, 1],\n",
    "                   [-2, 0, 2],\n",
    "                   [-1, 0, 1]])\n",
    "# sobel in y direction\n",
    "sobel_y= np.array([[-1,-2,-1],\n",
    "                   [0, 0, 0],\n",
    "                   [1, 2, 1]])\n",
    "# laplacian\n",
    "laplacian=np.array([[0, 1, 0],\n",
    "                    [1,-4, 1],\n",
    "                    [0, 1, 0]])\n",
    "\n",
    "filters = [mean_filter, gaussian, laplacian, sobel_x, sobel_y, scharr]\n",
    "filter_name = ['mean_filter', 'gaussian','laplacian', 'sobel_x', \\\n",
    "                'sobel_y', 'scharr_x']\n",
    "fft_filters = [np.fft.fft2(x) for x in filters]\n",
    "fft_shift = [np.fft.fftshift(y) for y in fft_filters]\n",
    "mag_spectrum = [np.log(np.abs(z)+1) for z in fft_shift]\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for i in xrange(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(mag_spectrum[i],cmap = 'gray')\n",
    "    plt.title(filter_name[i]), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From image, you can see what frequency region each kernel blocks, and what region it passes. From that information, we can say why each kernel is a HPF or a LPF."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
